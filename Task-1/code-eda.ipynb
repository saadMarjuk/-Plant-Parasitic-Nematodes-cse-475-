{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13370545,"sourceType":"datasetVersion","datasetId":8482306}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =========================================================\n# ‚úÖ Import Core Libraries\n# =========================================================\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport random\nfrom tqdm import tqdm\n\nprint(\"‚úÖ All imports successful!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:01:58.065348Z","iopub.execute_input":"2025-10-13T15:01:58.065575Z","iopub.status.idle":"2025-10-13T15:02:01.201793Z","shell.execute_reply.started":"2025-10-13T15:01:58.065549Z","shell.execute_reply":"2025-10-13T15:02:01.200795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üìÅ Dataset Directory\n# =========================================================\nbase_dir = \"/kaggle/input/saad-3/Microscopic Image Dataset of Plant-Parasitic Nematodes\"\n\n# Get class folders (each genus)\nclasses = sorted([d for d in os.listdir(base_dir) if d.startswith(\"Genus\")])\nprint(\"üîç Classes found:\", classes)\nprint(\"Total classes:\", len(classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:10:16.462470Z","iopub.execute_input":"2025-10-13T15:10:16.462751Z","iopub.status.idle":"2025-10-13T15:10:16.481693Z","shell.execute_reply.started":"2025-10-13T15:10:16.462730Z","shell.execute_reply":"2025-10-13T15:10:16.480900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üìä Count total images per class\n# =========================================================\nclass_counts = {}\nfor c in classes:\n    folder = os.path.join(base_dir, c)\n    class_counts[c] = len([f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n\ndf_counts = pd.DataFrame(list(class_counts.items()), columns=[\"Class\", \"Image_Count\"])\ndisplay(df_counts)\n\n# Plot class balance\nplt.figure(figsize=(10,5))\nsns.barplot(x=\"Class\", y=\"Image_Count\", data=df_counts, palette=\"viridis\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"Class Distribution of Nematode Images\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:10:35.918440Z","iopub.execute_input":"2025-10-13T15:10:35.918733Z","iopub.status.idle":"2025-10-13T15:10:36.655351Z","shell.execute_reply.started":"2025-10-13T15:10:35.918711Z","shell.execute_reply":"2025-10-13T15:10:36.654332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üñºÔ∏è Display Random Sample from Each Class\n# =========================================================\nplt.figure(figsize=(14, 8))\nfor i, c in enumerate(random.sample(classes, min(6, len(classes)))):\n    folder = os.path.join(base_dir, c)\n    img_path = os.path.join(folder, random.choice(os.listdir(folder)))\n    img = Image.open(img_path)\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img)\n    plt.title(c)\n    plt.axis(\"off\")\nplt.suptitle(\"Random Samples from Each Genus\", fontsize=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:11:12.023323Z","iopub.execute_input":"2025-10-13T15:11:12.024136Z","iopub.status.idle":"2025-10-13T15:11:14.571795Z","shell.execute_reply.started":"2025-10-13T15:11:12.024109Z","shell.execute_reply":"2025-10-13T15:11:14.570726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random sample image\nsample_class = random.choice(classes)\nfolder = os.path.join(base_dir, sample_class)\nsample_img_path = os.path.join(folder, random.choice(os.listdir(folder)))\nimg = cv2.imread(sample_img_path)\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Create subplots\nfig, axs = plt.subplots(2, 3, figsize=(14, 6))\n\n# RGB channels\nfor i, col in enumerate(['r', 'g', 'b']):\n    axs[0, i].hist(img_rgb[:, :, i].ravel(), bins=50, color=col)\n    axs[0, i].set_title(f\"RGB {col.upper()} Channel\")\n\n# HSV channels with valid colors\nhsv_colors = ['orange', 'green', 'blue']\nfor i, (col, title) in enumerate(zip(hsv_colors, [\"Hue\", \"Saturation\", \"Value\"])):\n    axs[1, i].hist(img_hsv[:, :, i].ravel(), bins=50, color=col)\n    axs[1, i].set_title(f\"HSV {title}\")\n\nplt.suptitle(f\"Color Distribution ‚Äî {sample_class}\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:13:30.998675Z","iopub.execute_input":"2025-10-13T15:13:30.998941Z","iopub.status.idle":"2025-10-13T15:13:32.306138Z","shell.execute_reply.started":"2025-10-13T15:13:30.998921Z","shell.execute_reply":"2025-10-13T15:13:32.305298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üìè Resolution & Aspect Ratio\n# =========================================================\nwidths, heights, aspects, labels = [], [], [], []\n\nfor c in tqdm(classes, desc=\"Analyzing sizes\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            img = cv2.imread(img_path)\n            if img is not None:\n                h, w = img.shape[:2]\n                widths.append(w)\n                heights.append(h)\n                aspects.append(w / h)\n                labels.append(c)\n\ndf_size = pd.DataFrame({\n    \"Class\": labels,\n    \"Width\": widths,\n    \"Height\": heights,\n    \"Aspect_Ratio\": aspects\n})\ndisplay(df_size.describe())\n\nplt.figure(figsize=(10,4))\nsns.histplot(df_size[\"Aspect_Ratio\"], bins=40, kde=True, color='green')\nplt.title(\"Aspect Ratio Distribution\")\nplt.xlabel(\"Width / Height\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:14:02.525623Z","iopub.execute_input":"2025-10-13T15:14:02.526323Z","iopub.status.idle":"2025-10-13T15:14:22.246095Z","shell.execute_reply.started":"2025-10-13T15:14:02.526287Z","shell.execute_reply":"2025-10-13T15:14:22.245258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üí° Brightness / Contrast / Sharpness Stats\n# =========================================================\nbrightness, contrast, sharpness, noise = [], [], [], []\n\nfor c in tqdm(classes, desc=\"Analyzing image stats\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            if img is not None:\n                brightness.append(np.mean(img))\n                contrast.append(np.std(img))\n                sharpness.append(cv2.Laplacian(img, cv2.CV_64F).var())\n                noise.append(np.mean(np.abs(img - cv2.medianBlur(img, 3))))\n\ndf_quality = pd.DataFrame({\n    \"Brightness\": brightness,\n    \"Contrast\": contrast,\n    \"Sharpness\": sharpness,\n    \"Noise\": noise\n})\n\ndisplay(df_quality.describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:15:26.594138Z","iopub.execute_input":"2025-10-13T15:15:26.594721Z","iopub.status.idle":"2025-10-13T15:15:50.179507Z","shell.execute_reply.started":"2025-10-13T15:15:26.594695Z","shell.execute_reply":"2025-10-13T15:15:50.178870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üé® Saturation clipping analysis (HSV S channel)\n# =========================================================\nsaturation_clipping = []\n\nfor c in tqdm(classes, desc=\"Saturation clipping per image\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            img = cv2.imread(img_path)\n            if img is not None:\n                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n                s = hsv[:, :, 1]\n                low_clip = np.sum(s == 0) / s.size * 100\n                high_clip = np.sum(s == 255) / s.size * 100\n                saturation_clipping.append({\n                    \"Class\": c,\n                    \"Image\": f,\n                    \"Low_Saturation_%\": low_clip,\n                    \"High_Saturation_%\": high_clip\n                })\n\ndf_saturation = pd.DataFrame(saturation_clipping)\ndisplay(df_saturation.describe())\n\n# Plot high saturation clipping per class\nplt.figure(figsize=(10,5))\nsns.boxplot(x=\"Class\", y=\"High_Saturation_%\", data=df_saturation, palette=\"magma\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"High Saturation (%) per Class\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:36:07.955884Z","iopub.execute_input":"2025-10-13T15:36:07.956147Z","iopub.status.idle":"2025-10-13T15:36:27.302135Z","shell.execute_reply.started":"2025-10-13T15:36:07.956129Z","shell.execute_reply":"2025-10-13T15:36:27.301387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üìè Resizing / padding analysis\n# =========================================================\ntarget_size = (256, 256)  # example standard size\nresized_widths, resized_heights = [], []\n\nfor c in tqdm(classes, desc=\"Resizing analysis\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            img = cv2.imread(img_path)\n            if img is not None:\n                h, w = img.shape[:2]\n                # Compute new size while maintaining aspect ratio\n                scale = min(target_size[0]/h, target_size[1]/w)\n                new_w, new_h = int(w*scale), int(h*scale)\n                resized_widths.append(new_w)\n                resized_heights.append(new_h)\n\ndf_resized = pd.DataFrame({\n    \"Resized_Width\": resized_widths,\n    \"Resized_Height\": resized_heights\n})\ndisplay(df_resized.describe())\n\n# Plot resized aspect ratio distribution\nplt.figure(figsize=(10,4))\nsns.histplot(np.array(resized_widths)/np.array(resized_heights), bins=40, kde=True, color='purple')\nplt.title(\"Resized Aspect Ratio Distribution\")\nplt.xlabel(\"Width / Height\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:37:53.693955Z","iopub.execute_input":"2025-10-13T15:37:53.694482Z","iopub.status.idle":"2025-10-13T15:38:04.503764Z","shell.execute_reply.started":"2025-10-13T15:37:53.694461Z","shell.execute_reply":"2025-10-13T15:38:04.503122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# ‚ö™ Gray-world white balance sanity check\n# =========================================================\ngray_world_deviation = []\n\nfor c in tqdm(classes, desc=\"Gray-world check\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            img = cv2.imread(img_path)\n            if img is not None:\n                mean_rgb = cv2.mean(img)[:3]  # BGR order\n                # Deviation from perfect gray (all channels equal)\n                deviation = np.std(mean_rgb)\n                gray_world_deviation.append({\n                    \"Class\": c,\n                    \"Image\": f,\n                    \"Gray_Deviation\": deviation\n                })\n\ndf_gray = pd.DataFrame(gray_world_deviation)\ndisplay(df_gray.describe())\n\n# Plot deviation per class\nplt.figure(figsize=(10,5))\nsns.boxplot(x=\"Class\", y=\"Gray_Deviation\", data=df_gray, palette=\"coolwarm\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"Gray-World Deviation per Class (White-Balance Check)\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:38:26.343093Z","iopub.execute_input":"2025-10-13T15:38:26.343386Z","iopub.status.idle":"2025-10-13T15:38:39.446309Z","shell.execute_reply.started":"2025-10-13T15:38:26.343367Z","shell.execute_reply":"2025-10-13T15:38:39.445646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üîç Duplicate detection using phash\n# =========================================================\nfrom collections import defaultdict\nimport imagehash\nfrom PIL import Image\n\nhash_dict = defaultdict(list)\nduplicates = []\n\nfor c in tqdm(classes, desc=\"Computing phash\"):\n    folder = os.path.join(base_dir, c)\n    for f in os.listdir(folder):\n        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(folder, f)\n            try:\n                img = Image.open(img_path)\n                h = imagehash.phash(img)\n                if h in hash_dict:\n                    duplicates.append((f, hash_dict[h]))\n                hash_dict[h].append(f)\n            except:\n                continue\n\nprint(f\"Total potential duplicates found: {len(duplicates)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:39:55.275510Z","iopub.execute_input":"2025-10-13T15:39:55.275785Z","iopub.status.idle":"2025-10-13T15:40:12.774327Z","shell.execute_reply.started":"2025-10-13T15:39:55.275766Z","shell.execute_reply":"2025-10-13T15:40:12.773652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# üîÑ Small augmentation probe\n# =========================================================\nfrom PIL import ImageEnhance, ImageFilter\n\nsample_class = random.choice(classes)\nfolder = os.path.join(base_dir, sample_class)\nimg_path = os.path.join(folder, random.choice(os.listdir(folder)))\nimg = Image.open(img_path)\n\nplt.figure(figsize=(12,4))\nplt.subplot(1,5,1)\nplt.imshow(img)\nplt.title(\"Original\")\nplt.axis(\"off\")\n\n# Horizontal flip\nplt.subplot(1,5,2)\nplt.imshow(img.transpose(Image.FLIP_LEFT_RIGHT))\nplt.title(\"H-Flip\")\nplt.axis(\"off\")\n\n# Random crop\nplt.subplot(1,5,3)\nw, h = img.size\ncrop_img = img.crop((w//8, h//8, w*7//8, h*7//8))\nplt.imshow(crop_img)\nplt.title(\"Center Crop\")\nplt.axis(\"off\")\n\n# Brightness increase\nplt.subplot(1,5,4)\nenh = ImageEnhance.Brightness(img).enhance(1.5)\nplt.imshow(enh)\nplt.title(\"Brightness +50%\")\nplt.axis(\"off\")\n\n# Blur\nplt.subplot(1,5,5)\nblur = img.filter(ImageFilter.GaussianBlur(radius=2))\nplt.imshow(blur)\nplt.title(\"Gaussian Blur\")\nplt.axis(\"off\")\n\nplt.suptitle(f\"Augmentation Probe ‚Äî {sample_class}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T15:43:57.989465Z","iopub.execute_input":"2025-10-13T15:43:57.989735Z","iopub.status.idle":"2025-10-13T15:43:58.977141Z","shell.execute_reply.started":"2025-10-13T15:43:57.989717Z","shell.execute_reply":"2025-10-13T15:43:58.976472Z"}},"outputs":[],"execution_count":null}]}