{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13370545,"sourceType":"datasetVersion","datasetId":8482306}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Safe optional installs (ONLY if missing) + restart runtime\nimport sys, os, signal, importlib.util, subprocess\n\ndef pip_install(pkg):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n\n# Install scikit-posthocs ONLY if it's missing\nif importlib.util.find_spec(\"scikit_posthocs\") is None:\n    pip_install(\"scikit-posthocs\")\n\n# IMPORTANT: restart runtime to avoid torch duplicate registration bug\nos.kill(os.getpid(), signal.SIGKILL)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-15T20:22:50.885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Imports (run AFTER restart)\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import stats\nfrom scipy.stats import wilcoxon, friedmanchisquare\nimport scikit_posthocs as sp\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms, models\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\nprint(\"Torch:\", torch.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:22:56.673646Z","iopub.execute_input":"2025-12-15T20:22:56.674328Z","iopub.status.idle":"2025-12-15T20:23:00.434334Z","shell.execute_reply.started":"2025-12-15T20:22:56.674302Z","shell.execute_reply":"2025-12-15T20:23:00.433442Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nTorch: 2.6.0+cu124\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load Dataset and Setup\n# ============================================================================\n\nDATA_DIR = \"/kaggle/input/saad-3/Microscopic Image Dataset of Plant-Parasitic Nematodes\"\nbase_ds = datasets.ImageFolder(DATA_DIR)\ny_all = np.array(base_ds.targets)\nn = len(base_ds)\nnum_classes = len(base_ds.classes)\n\nprint(f\"Total samples: {n}, Classes: {num_classes}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:06.477476Z","iopub.execute_input":"2025-12-15T20:23:06.478149Z","iopub.status.idle":"2025-12-15T20:23:06.965384Z","shell.execute_reply.started":"2025-12-15T20:23:06.478123Z","shell.execute_reply":"2025-12-15T20:23:06.964645Z"}},"outputs":[{"name":"stdout","text":"Total samples: 1016, Classes: 11\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Cell 3: Define Train:Test Split Ratios (Same as Task 2)\n# ============================================================================\n\n# Multiple train:test ratios for comprehensive evaluation\nsplit_ratios = [\n    {\"train\": 0.6, \"test\": 0.4, \"name\": \"60:40\"},\n    {\"train\": 0.7, \"test\": 0.3, \"name\": \"70:30\"},\n    {\"train\": 0.8, \"test\": 0.2, \"name\": \"80:20\"},\n]\n\nprint(\"Split ratios:\", [r[\"name\"] for r in split_ratios])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:09.563143Z","iopub.execute_input":"2025-12-15T20:23:09.563836Z","iopub.status.idle":"2025-12-15T20:23:09.568494Z","shell.execute_reply.started":"2025-12-15T20:23:09.563814Z","shell.execute_reply":"2025-12-15T20:23:09.567662Z"}},"outputs":[{"name":"stdout","text":"Split ratios: ['60:40', '70:30', '80:20']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: SimCLR Model Definition\n# ============================================================================\n\nclass TwoCropsTransform:\n    def __init__(self, base_transform):\n        self.base_transform = base_transform\n    def __call__(self, x):\n        return self.base_transform(x), self.base_transform(x)\n\nclass SimCLR(nn.Module):\n    def __init__(self, base_encoder, out_dim=128, proj_hidden=512):\n        super().__init__()\n        self.encoder = base_encoder\n        num_ftrs = self.encoder.fc.in_features\n        self.encoder.fc = nn.Identity()\n        self.proj = nn.Sequential(\n            nn.Linear(num_ftrs, proj_hidden),\n            nn.ReLU(inplace=True),\n            nn.Linear(proj_hidden, out_dim)\n        )\n    def forward(self, x):\n        h = self.encoder(x)\n        z = self.proj(h)\n        return F.normalize(z, dim=1)\n\ndef nt_xent_loss(z_i, z_j, temperature=0.5):\n    N = z_i.size(0)\n    z = torch.cat([z_i, z_j], dim=0)\n    sim = torch.mm(z, z.t()) / temperature\n    mask = torch.eye(2*N, device=z.device, dtype=torch.bool)\n    sim = sim.masked_fill(mask, -1e9)\n    targets = torch.arange(2*N, device=z.device)\n    targets = (targets + N) % (2*N)\n    return F.cross_entropy(sim, targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:11.690508Z","iopub.execute_input":"2025-12-15T20:23:11.691140Z","iopub.status.idle":"2025-12-15T20:23:11.699611Z","shell.execute_reply.started":"2025-12-15T20:23:11.691108Z","shell.execute_reply":"2025-12-15T20:23:11.698829Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Cell 5: Augmentation Configurations for Ablations\n# ============================================================================\n\ndef get_simclr_transform(config_name=\"full\"):\n    \"\"\"\n    Returns different augmentation configurations for ablation study.\n    \n    Configs:\n    - full: All augmentations (baseline)\n    - no_color: Remove ColorJitter\n    - no_blur: Remove GaussianBlur\n    - no_grayscale: Remove RandomGrayscale\n    - minimal: Only crop + flip\n    \"\"\"\n    base_augs = [\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n    ]\n    \n    if config_name == \"full\":\n        augs = base_augs + [\n            transforms.RandomRotation(20),\n            transforms.RandomApply([transforms.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.GaussianBlur(kernel_size=9),\n        ]\n    elif config_name == \"no_color\":\n        augs = base_augs + [\n            transforms.RandomRotation(20),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.GaussianBlur(kernel_size=9),\n        ]\n    elif config_name == \"no_blur\":\n        augs = base_augs + [\n            transforms.RandomRotation(20),\n            transforms.RandomApply([transforms.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n            transforms.RandomGrayscale(p=0.2),\n        ]\n    elif config_name == \"no_grayscale\":\n        augs = base_augs + [\n            transforms.RandomRotation(20),\n            transforms.RandomApply([transforms.ColorJitter(0.4,0.4,0.4,0.1)], p=0.8),\n            transforms.GaussianBlur(kernel_size=9),\n        ]\n    elif config_name == \"minimal\":\n        augs = base_augs\n    else:\n        raise ValueError(f\"Unknown config: {config_name}\")\n    \n    augs += [\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n    ]\n    \n    return transforms.Compose(augs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:20.168229Z","iopub.execute_input":"2025-12-15T20:23:20.168921Z","iopub.status.idle":"2025-12-15T20:23:20.175446Z","shell.execute_reply.started":"2025-12-15T20:23:20.168899Z","shell.execute_reply":"2025-12-15T20:23:20.174578Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Cell 6: Training Function for SimCLR\n# ============================================================================\n\ndef train_simclr(train_loader, epochs=30, lr=3e-4, temperature=0.5, \n                 proj_hidden=512, out_dim=128, batch_size=64):\n    \"\"\"\n    Train SimCLR model and return trained encoder.\n    \"\"\"\n    resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n    ssl_model = SimCLR(resnet50, out_dim=out_dim, proj_hidden=proj_hidden).to(device)\n    optimizer = optim.Adam(ssl_model.parameters(), lr=lr, weight_decay=1e-4)\n    \n    loss_hist = []\n    \n    for epoch in range(epochs):\n        ssl_model.train()\n        total = 0.0\n        for (xi, xj), _ in train_loader:\n            xi, xj = xi.to(device), xj.to(device)\n            zi = ssl_model(xi)\n            zj = ssl_model(xj)\n            loss = nt_xent_loss(zi, zj, temperature=temperature)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total += loss.item()\n        \n        avg_loss = total / len(train_loader)\n        loss_hist.append(avg_loss)\n        \n        if (epoch + 1) % 10 == 0 or epoch == 0:\n            print(f\"  Epoch {epoch+1}/{epochs} loss={avg_loss:.4f}\")\n    \n    # Return frozen encoder\n    for p in ssl_model.encoder.parameters():\n        p.requires_grad = False\n    ssl_model.encoder.eval()\n    \n    return ssl_model.encoder, loss_hist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:23.595317Z","iopub.execute_input":"2025-12-15T20:23:23.595812Z","iopub.status.idle":"2025-12-15T20:23:23.602616Z","shell.execute_reply.started":"2025-12-15T20:23:23.595788Z","shell.execute_reply":"2025-12-15T20:23:23.601523Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 7: Feature Extraction Function\n# ============================================================================\n\ndef extract_features(encoder, loader):\n    \"\"\"Extract frozen features from encoder.\"\"\"\n    encoder.eval()\n    feats, labels = [], []\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            f = encoder(x).cpu()\n            feats.append(f)\n            labels.append(y)\n    return torch.cat(feats).numpy(), torch.cat(labels).numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:26.435460Z","iopub.execute_input":"2025-12-15T20:23:26.435733Z","iopub.status.idle":"2025-12-15T20:23:26.440403Z","shell.execute_reply.started":"2025-12-15T20:23:26.435715Z","shell.execute_reply":"2025-12-15T20:23:26.439590Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 8: Evaluation Functions\n# ============================================================================\n\ndef eval_linear_probe(X_train, y_train, X_test, y_test):\n    \"\"\"Evaluate linear probe (logistic regression).\"\"\"\n    clf = make_pipeline(\n        StandardScaler(),\n        LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n    )\n    \n    t0 = time.time()\n    clf.fit(X_train, y_train)\n    train_time = time.time() - t0\n    \n    t0 = time.time()\n    y_pred = clf.predict(X_test)\n    test_time = time.time() - t0\n    \n    acc = accuracy_score(y_test, y_pred)\n    \n    return {\n        'accuracy': acc,\n        'train_time': train_time,\n        'test_time': test_time,\n        'model': clf\n    }\n\ndef eval_knn(X_train, y_train, X_test, y_test, k=5):\n    \"\"\"Evaluate k-NN classifier.\"\"\"\n    clf = make_pipeline(\n        StandardScaler(),\n        KNeighborsClassifier(n_neighbors=k)\n    )\n    clf.fit(X_train, y_train)\n    acc = clf.score(X_test, y_test)\n    return acc\n\ndef eval_label_efficiency(X_train, y_train, X_test, y_test, ratios=[0.01, 0.05, 0.10, 0.25, 0.50]):\n    \"\"\"Evaluate performance with different amounts of labeled data.\"\"\"\n    results = {}\n    rng = np.random.default_rng(42)\n    classes = np.unique(y_train)\n    \n    for r in ratios:\n        X_small, y_small = [], []\n        for c in classes:\n            idx_c = np.where(y_train == c)[0]\n            m = max(1, int(len(idx_c) * r))\n            chosen = rng.choice(idx_c, m, replace=False)\n            X_small.append(X_train[chosen])\n            y_small.append(y_train[chosen])\n        \n        X_small = np.vstack(X_small)\n        y_small = np.hstack(y_small)\n        \n        clf = make_pipeline(\n            StandardScaler(),\n            LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n        )\n        clf.fit(X_small, y_small)\n        acc = clf.score(X_test, y_test)\n        results[r] = acc\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:29.819372Z","iopub.execute_input":"2025-12-15T20:23:29.819987Z","iopub.status.idle":"2025-12-15T20:23:29.827861Z","shell.execute_reply.started":"2025-12-15T20:23:29.819964Z","shell.execute_reply":"2025-12-15T20:23:29.827018Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Cell 9: Ablation Study Configuration\n# ============================================================================\n\nablation_configs = [\n    {\n        \"name\": \"Baseline (Full)\",\n        \"aug_config\": \"full\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Full augmentation pipeline\"\n    },\n    {\n        \"name\": \"No Color Jitter\",\n        \"aug_config\": \"no_color\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Remove ColorJitter augmentation\"\n    },\n    {\n        \"name\": \"No Gaussian Blur\",\n        \"aug_config\": \"no_blur\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Remove GaussianBlur augmentation\"\n    },\n    {\n        \"name\": \"Minimal Augmentation\",\n        \"aug_config\": \"minimal\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Only Crop + Flip\"\n    },\n    {\n        \"name\": \"Small Batch\",\n        \"aug_config\": \"full\",\n        \"epochs\": 30,\n        \"batch_size\": 32,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Batch size 32 instead of 64\"\n    },\n    {\n        \"name\": \"Shallow Projection\",\n        \"aug_config\": \"full\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.5,\n        \"proj_hidden\": 256,\n        \"out_dim\": 128,\n        \"description\": \"Smaller projection head (256 hidden)\"\n    },\n    {\n        \"name\": \"Higher Temperature\",\n        \"aug_config\": \"full\",\n        \"epochs\": 30,\n        \"batch_size\": 64,\n        \"lr\": 3e-4,\n        \"temperature\": 0.7,\n        \"proj_hidden\": 512,\n        \"out_dim\": 128,\n        \"description\": \"Temperature = 0.7 instead of 0.5\"\n    },\n]\n\nprint(f\"Total ablation configurations: {len(ablation_configs)}\")\nfor i, cfg in enumerate(ablation_configs):\n    print(f\"{i+1}. {cfg['name']}: {cfg['description']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:23:34.283424Z","iopub.execute_input":"2025-12-15T20:23:34.283693Z","iopub.status.idle":"2025-12-15T20:23:34.291344Z","shell.execute_reply.started":"2025-12-15T20:23:34.283675Z","shell.execute_reply":"2025-12-15T20:23:34.290517Z"}},"outputs":[{"name":"stdout","text":"Total ablation configurations: 7\n1. Baseline (Full): Full augmentation pipeline\n2. No Color Jitter: Remove ColorJitter augmentation\n3. No Gaussian Blur: Remove GaussianBlur augmentation\n4. Minimal Augmentation: Only Crop + Flip\n5. Small Batch: Batch size 32 instead of 64\n6. Shallow Projection: Smaller projection head (256 hidden)\n7. Higher Temperature: Temperature = 0.7 instead of 0.5\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Cell 10: Run Complete Ablation Study Across All Splits\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"RUNNING COMPLETE ABLATION STUDY\")\nprint(\"=\"*80)\n\nall_results = []\n\n# Evaluation transform (same for all)\neval_tf = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\n\nfor split_idx, split_cfg in enumerate(split_ratios):\n    print(f\"\\n{'='*80}\")\n    print(f\"SPLIT {split_idx+1}/{len(split_ratios)}: {split_cfg['name']}\")\n    print(f\"{'='*80}\")\n    \n    # Create split\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=split_cfg['test'], random_state=42)\n    train_idx, test_idx = next(sss.split(np.zeros(n), y_all))\n    train_idx = np.array(train_idx)\n    test_idx = np.array(test_idx)\n    \n    print(f\"Train samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n    \n    # Create probe datasets (for feature extraction)\n    probe_ds = datasets.ImageFolder(DATA_DIR, transform=eval_tf)\n    train_probe = Subset(probe_ds, train_idx)\n    test_probe = Subset(probe_ds, test_idx)\n    \n    train_probe_loader = DataLoader(train_probe, batch_size=64, shuffle=False, num_workers=2)\n    test_probe_loader = DataLoader(test_probe, batch_size=64, shuffle=False, num_workers=2)\n    \n    for abl_idx, abl_cfg in enumerate(ablation_configs):\n        print(f\"\\n{'-'*80}\")\n        print(f\"Ablation {abl_idx+1}/{len(ablation_configs)}: {abl_cfg['name']}\")\n        print(f\"Description: {abl_cfg['description']}\")\n        print(f\"{'-'*80}\")\n        \n        # Create SSL training dataset with specific augmentation\n        simclr_transform = get_simclr_transform(abl_cfg['aug_config'])\n        ssl_ds = datasets.ImageFolder(DATA_DIR, transform=TwoCropsTransform(simclr_transform))\n        train_ssl = Subset(ssl_ds, train_idx)\n        \n        # Create SSL dataloader\n        train_ssl_loader = DataLoader(\n            train_ssl, \n            batch_size=abl_cfg['batch_size'], \n            shuffle=True, \n            num_workers=2, \n            drop_last=True\n        )\n        \n        # Train SimCLR\n        print(f\"Training SimCLR...\")\n        start_time = time.time()\n        encoder, loss_hist = train_simclr(\n            train_ssl_loader,\n            epochs=abl_cfg['epochs'],\n            lr=abl_cfg['lr'],\n            temperature=abl_cfg['temperature'],\n            proj_hidden=abl_cfg['proj_hidden'],\n            out_dim=abl_cfg['out_dim'],\n            batch_size=abl_cfg['batch_size']\n        )\n        ssl_train_time = time.time() - start_time\n        print(f\"SSL training completed in {ssl_train_time:.2f}s\")\n        \n        # Extract features\n        print(\"Extracting features...\")\n        X_train, y_train = extract_features(encoder, train_probe_loader)\n        X_test, y_test = extract_features(encoder, test_probe_loader)\n        \n        # Evaluate Linear Probe\n        print(\"Evaluating linear probe...\")\n        linear_results = eval_linear_probe(X_train, y_train, X_test, y_test)\n        \n        # Evaluate k-NN\n        print(\"Evaluating k-NN (k=5)...\")\n        knn_acc = eval_knn(X_train, y_train, X_test, y_test, k=5)\n        \n        # Evaluate Label Efficiency\n        print(\"Evaluating label efficiency...\")\n        label_eff = eval_label_efficiency(X_train, y_train, X_test, y_test)\n        \n        # Store results\n        result = {\n            'split_name': split_cfg['name'],\n            'split_train_ratio': split_cfg['train'],\n            'ablation_name': abl_cfg['name'],\n            'ablation_config': abl_cfg['description'],\n            'aug_config': abl_cfg['aug_config'],\n            'batch_size': abl_cfg['batch_size'],\n            'temperature': abl_cfg['temperature'],\n            'proj_hidden': abl_cfg['proj_hidden'],\n            'ssl_train_time': ssl_train_time,\n            'final_ssl_loss': loss_hist[-1],\n            'linear_probe_acc': linear_results['accuracy'],\n            'linear_probe_train_time': linear_results['train_time'],\n            'knn5_acc': knn_acc,\n            'label_eff_1pct': label_eff[0.01],\n            'label_eff_5pct': label_eff[0.05],\n            'label_eff_10pct': label_eff[0.10],\n            'label_eff_25pct': label_eff[0.25],\n            'label_eff_50pct': label_eff[0.50],\n        }\n        \n        all_results.append(result)\n        \n        print(f\"\\nResults Summary:\")\n        print(f\"  Linear Probe Acc: {linear_results['accuracy']:.4f}\")\n        print(f\"  k-NN (k=5) Acc: {knn_acc:.4f}\")\n        print(f\"  Label Eff (10%): {label_eff[0.10]:.4f}\")\n        \n        # Clean up\n        del encoder, ssl_ds, train_ssl, train_ssl_loader\n        torch.cuda.empty_cache()\n\n# Convert to DataFrame\nresults_df = pd.DataFrame(all_results)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ABLATION STUDY COMPLETED\")\nprint(\"=\"*80)\nprint(f\"Total experiments run: {len(results_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:05:06.690701Z","iopub.status.idle":"2025-12-16T06:05:06.690982Z","shell.execute_reply.started":"2025-12-16T06:05:06.690852Z","shell.execute_reply":"2025-12-16T06:05:06.690863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Display Consolidated Results Table\n# ============================================================================\n\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CONSOLIDATED RESULTS TABLE\")\nprint(\"=\"*80)\n\n# Create summary table\nsummary_cols = [\n    'split_name', 'ablation_name', 'linear_probe_acc', 'knn5_acc',\n    'label_eff_10pct', 'ssl_train_time', 'final_ssl_loss'\n]\n\nsummary_df = results_df[summary_cols].copy()\nsummary_df = summary_df.round(4)\n\nprint(\"\\n\", summary_df.to_string(index=False))\n\n# Save results\nresults_df.to_csv('ablation_results_simclr.csv', index=False)\nprint(\"\\nResults saved to: ablation_results_simclr.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:05:06.691807Z","iopub.status.idle":"2025-12-16T06:05:06.692050Z","shell.execute_reply.started":"2025-12-16T06:05:06.691947Z","shell.execute_reply":"2025-12-16T06:05:06.691959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: Statistical Analysis - Setup\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STATISTICAL ANALYSIS\")\nprint(\"=\"*80)\n\n# For statistical tests, we need to compare models across the same splits\n# We'll use each split as a \"sample\" for paired tests\n\n# Pivot data for easier analysis\npivot_linear = results_df.pivot(\n    index='split_name',\n    columns='ablation_name',\n    values='linear_probe_acc'\n)\n\npivot_knn = results_df.pivot(\n    index='split_name',\n    columns='ablation_name',\n    values='knn5_acc'\n)\n\npivot_label_eff = results_df.pivot(\n    index='split_name',\n    columns='ablation_name',\n    values='label_eff_10pct'\n)\n\nprint(\"\\nLinear Probe Accuracy by Split and Ablation:\")\nprint(pivot_linear)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:05:06.692831Z","iopub.status.idle":"2025-12-16T06:05:06.693044Z","shell.execute_reply.started":"2025-12-16T06:05:06.692943Z","shell.execute_reply":"2025-12-16T06:05:06.692953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13: Paired t-tests (Baseline vs Each Ablation)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PAIRED T-TESTS: Baseline vs Each Ablation\")\nprint(\"=\"*80)\n\nbaseline_name = \"Baseline (Full)\"\n\nif baseline_name in pivot_linear.columns:\n    baseline_scores = pivot_linear[baseline_name].values\n    \n    print(\"\\nLinear Probe Accuracy:\")\n    print(\"-\" * 60)\n    \n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            \n            # Paired t-test\n            t_stat, p_value = stats.ttest_rel(baseline_scores, comparison_scores)\n            \n            mean_baseline = np.mean(baseline_scores)\n            mean_comparison = np.mean(comparison_scores)\n            diff = mean_comparison - mean_baseline\n            \n            # Effect size (Cohen's d for paired samples)\n            std_diff = np.std(baseline_scores - comparison_scores, ddof=1)\n            cohens_d = diff / std_diff if std_diff > 0 else 0\n            \n            sig_marker = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n            \n            print(f\"\\n{baseline_name} vs {col}:\")\n            print(f\"  Baseline mean: {mean_baseline:.4f}\")\n            print(f\"  Comparison mean: {mean_comparison:.4f}\")\n            print(f\"  Difference: {diff:+.4f}\")\n            print(f\"  t-statistic: {t_stat:.4f}\")\n            print(f\"  p-value: {p_value:.4f} {sig_marker}\")\n            print(f\"  Cohen's d: {cohens_d:.4f}\")\n            \n            if p_value < 0.05:\n                direction = \"better\" if diff > 0 else \"worse\"\n                print(f\"  → Statistically significant: {col} is {direction} than baseline\")\n            else:\n                print(f\"  → No significant difference\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T06:05:06.728535Z","iopub.execute_input":"2025-12-16T06:05:06.728784Z","iopub.status.idle":"2025-12-16T06:05:06.740015Z","shell.execute_reply.started":"2025-12-16T06:05:06.728767Z","shell.execute_reply":"2025-12-16T06:05:06.739153Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nPAIRED T-TESTS: Baseline vs Each Ablation\n================================================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1708293348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbaseline_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Baseline (Full)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mbaseline_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpivot_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbaseline_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivot_linear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbaseline_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pivot_linear' is not defined"],"ename":"NameError","evalue":"name 'pivot_linear' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Cell 14: Friedman Test (Multiple Models Comparison)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FRIEDMAN TEST: Comparing All Ablations\")\nprint(\"=\"*80)\n\n# Friedman test for linear probe accuracy\nprint(\"\\nLinear Probe Accuracy:\")\nprint(\"-\" * 60)\n\n# Prepare data: each row is a split, each column is an ablation\nfriedman_data = [pivot_linear[col].values for col in pivot_linear.columns]\n\ntry:\n    stat, p_value = friedmanchisquare(*friedman_data)\n    \n    print(f\"Friedman chi-square: {stat:.4f}\")\n    print(f\"p-value: {p_value:.4f}\")\n    \n    if p_value < 0.05:\n        print(\"→ Significant differences detected among ablations (p < 0.05)\")\n        print(\"\\nPerforming Nemenyi post-hoc test...\")\n        \n        # Nemenyi post-hoc test\n        nemenyi_result = sp.posthoc_nemenyi_friedman(pivot_linear)\n        \n        print(\"\\nNemenyi post-hoc p-values:\")\n        print(nemenyi_result.round(4))\n        \n        # Identify significantly different pairs\n        print(\"\\nSignificant pairwise differences (p < 0.05):\")\n        sig_pairs = []\n        for i in range(len(nemenyi_result.columns)):\n            for j in range(i+1, len(nemenyi_result.columns)):\n                col_i = nemenyi_result.columns[i]\n                col_j = nemenyi_result.columns[j]\n                p_val = nemenyi_result.iloc[i, j]\n                \n                if p_val < 0.05:\n                    mean_i = pivot_linear[col_i].mean()\n                    mean_j = pivot_linear[col_j].mean()\n                    better = col_i if mean_i > mean_j else col_j\n                    worse = col_j if mean_i > mean_j else col_i\n                    sig_pairs.append((better, worse, p_val))\n        \n        if sig_pairs:\n            for better, worse, p_val in sig_pairs:\n                print(f\"  {better} > {worse} (p={p_val:.4f})\")\n        else:\n            print(\"  No pairwise differences significant at p < 0.05\")\n    else:\n        print(\"→ No significant differences among ablations (p >= 0.05)\")\n\nexcept Exception as e:\n    print(f\"Error in Friedman test: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15: Effect Sizes - Calculate and Visualize\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EFFECT SIZES (vs Baseline)\")\nprint(\"=\"*80)\n\nif baseline_name in pivot_linear.columns:\n    baseline_scores = pivot_linear[baseline_name].values\n    \n    effect_sizes = []\n    \n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            \n            # Cohen's d\n            diff = np.mean(comparison_scores) - np.mean(baseline_scores)\n            std_diff = np.std(baseline_scores - comparison_scores, ddof=1)\n            cohens_d = diff / std_diff if std_diff > 0 else 0\n            \n            # Practical significance threshold\n            practical_sig = abs(diff) > 0.02  # 2% accuracy difference\n            \n            effect_sizes.append({\n                'ablation': col,\n                'mean_diff': diff,\n                'cohens_d': cohens_d,\n                'practical_sig': practical_sig\n            })\n    \n    effect_df = pd.DataFrame(effect_sizes)\n    effect_df = effect_df.sort_values('mean_diff', ascending=False)\n    \n    print(\"\\n\", effect_df.to_string(index=False))\n    \n    # Visualize effect sizes\n    plt.figure(figsize=(10, 6))\n    colors = ['green' if x > 0 else 'red' for x in effect_df['mean_diff']]\n    plt.barh(effect_df['ablation'], effect_df['mean_diff'], color=colors, alpha=0.7)\n    plt.xlabel('Difference in Linear Probe Accuracy (vs Baseline)')\n    plt.title('Effect Sizes: Ablation Impact on Performance')\n    plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n    plt.axvline(x=0.02, color='gray', linestyle=':', linewidth=1, label='Practical significance (+2%)')\n    plt.axvline(x=-0.02, color='gray', linestyle=':', linewidth=1)\n    plt.legend()\n    plt.tight_layout()\n    plt.grid(axis='x', alpha=0.3)\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16: Visualization - Ablation Comparison Across Splits\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZATION: Performance Across Splits\")\nprint(\"=\"*80)\n\n# Plot 1: Linear Probe Accuracy by Split\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nmetrics = [\n    ('linear_probe_acc', 'Linear Probe Accuracy'),\n    ('knn5_acc', 'k-NN (k=5) Accuracy'),\n    ('label_eff_10pct', 'Label Efficiency (10%)')\n]\n\nfor idx, (metric, title) in enumerate(metrics):\n    ax = axes[idx]\n    \n    for abl_name in results_df['ablation_name'].unique():\n        subset = results_df[results_df['ablation_name'] == abl_name]\n        ax.plot(subset['split_name'], subset[metric], marker='o', label=abl_name, linewidth=2)\n    \n    ax.set_xlabel('Train:Test Split')\n    ax.set_ylabel('Accuracy')\n    ax.set_title(title)\n    ax.legend(fontsize=8, loc='best')\n    ax.grid(True, alpha=0.3)\n    ax.set_ylim([0, 1])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17: Visualization - Label Efficiency Curves\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZATION: Label Efficiency Curves\")\nprint(\"=\"*80)\n\n# For the 80:20 split, plot label efficiency curves\nsplit_80_20 = results_df[results_df['split_name'] == '80:20']\n\nlabel_ratios = [0.01, 0.05, 0.10, 0.25, 0.50]\nlabel_pcts = [r * 100 for r in label_ratios]\n\nplt.figure(figsize=(10, 6))\n\nfor abl_name in split_80_20['ablation_name'].unique():\n    row = split_80_20[split_80_20['ablation_name'] == abl_name].iloc[0]\n    \n    accs = [\n        row['label_eff_1pct'],\n        row['label_eff_5pct'],\n        row['label_eff_10pct'],\n        row['label_eff_25pct'],\n        row['label_eff_50pct']\n    ]\n    \n    plt.plot(label_pcts, accs, marker='o', label=abl_name, linewidth=2)\n\nplt.xlabel('Percentage of Labeled Training Data')\nplt.ylabel('Linear Probe Accuracy')\nplt.title('Label Efficiency Curves (80:20 Split)')\nplt.legend(fontsize=9, loc='lower right')\nplt.grid(True, alpha=0.3)\nplt.xlim([0, 55])\nplt.ylim([0, 1])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18: Visualization - Heatmap of Results\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VISUALIZATION: Results Heatmap\")\nprint(\"=\"*80)\n\n# Create heatmap for linear probe accuracy\nfig, ax = plt.subplots(figsize=(10, 6))\n\nheatmap_data = results_df.pivot(\n    index='ablation_name',\n    columns='split_name',\n    values='linear_probe_acc'\n)\n\nsns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n            vmin=0.5, vmax=0.85, ax=ax, cbar_kws={'label': 'Accuracy'})\nax.set_title('Linear Probe Accuracy: Ablations × Splits')\nax.set_xlabel('Train:Test Split')\nax.set_ylabel('Ablation Configuration')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 19: Summary Statistics Table\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY STATISTICS BY ABLATION\")\nprint(\"=\"*80)\n\nsummary_stats = results_df.groupby('ablation_name').agg({\n    'linear_probe_acc': ['mean', 'std', 'min', 'max'],\n    'knn5_acc': ['mean', 'std'],\n    'label_eff_10pct': ['mean', 'std'],\n    'ssl_train_time': ['mean']\n}).round(4)\n\nprint(\"\\n\", summary_stats)\n\n# Rank ablations by mean linear probe accuracy\nrankings = results_df.groupby('ablation_name')['linear_probe_acc'].mean().sort_values(ascending=False)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ABLATION RANKINGS (by mean Linear Probe Accuracy)\")\nprint(\"=\"*80)\n\nfor rank, (abl_name, score) in enumerate(rankings.items(), 1):\n    print(f\"{rank}. {abl_name}: {score:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 20: Practical vs Statistical Significance Analysis\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PRACTICAL vs STATISTICAL SIGNIFICANCE\")\nprint(\"=\"*80)\n\nif baseline_name in pivot_linear.columns:\n    baseline_mean = pivot_linear[baseline_name].mean()\n    \n    print(f\"\\nBaseline mean accuracy: {baseline_mean:.4f}\")\n    print(\"\\nAnalyzing each ablation:\")\n    print(\"-\" * 60)\n    \n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            baseline_scores = pivot_linear[baseline_name].values\n            \n            # Statistical test\n            t_stat, p_value = stats.ttest_rel(baseline_scores, comparison_scores)\n            statistically_sig = p_value < 0.05\n            \n            # Practical significance (2% threshold)\n            mean_comparison = comparison_scores.mean()\n            diff = mean_comparison - baseline_mean\n            practically_sig = abs(diff) > 0.02\n            \n            print(f\"\\n{col}:\")\n            print(f\"  Mean accuracy: {mean_comparison:.4f} ({diff:+.4f})\")\n            print(f\"  Statistical significance: {'YES (p={:.4f})'.format(p_value) if statistically_sig else 'NO (p={:.4f})'.format(p_value)}\")\n            print(f\"  Practical significance: {'YES (|diff|={:.4f})'.format(abs(diff)) if practically_sig else 'NO (|diff|={:.4f})'.format(abs(diff))}\")\n            \n            # Interpretation\n            if statistically_sig and practically_sig:\n                print(f\"  → BOTH statistically and practically significant\")\n            elif statistically_sig and not practically_sig:\n                print(f\"  → Statistically significant but NOT practically significant\")\n            elif not statistically_sig and practically_sig:\n                print(f\"  → Practically significant but NOT statistically significant (may need more samples)\")\n            else:\n                print(f\"  → Neither statistically nor practically significant\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 21: Key Findings Summary\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"KEY FINDINGS SUMMARY\")\nprint(\"=\"*80)\n\nprint(\"\\n1. BEST PERFORMING ABLATIONS:\")\ntop_3 = rankings.head(3)\nfor rank, (abl_name, score) in enumerate(top_3.items(), 1):\n    print(f\"   {rank}. {abl_name}: {score:.4f}\")\n\nprint(\"\\n2. WORST PERFORMING ABLATIONS:\")\nbottom_3 = rankings.tail(3)\nfor rank, (abl_name, score) in enumerate(bottom_3.items(), 1):\n    print(f\"   {rank}. {abl_name}: {score:.4f}\")\n\nprint(\"\\n3. MOST IMPACTFUL ABLATIONS (vs Baseline):\")\nif baseline_name in pivot_linear.columns:\n    baseline_scores = pivot_linear[baseline_name].values\n    impacts = []\n    \n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            diff = comparison_scores.mean() - baseline_scores.mean()\n            impacts.append((col, diff))\n    \n    impacts.sort(key=lambda x: abs(x[1]), reverse=True)\n    \n    for abl_name, diff in impacts[:3]:\n        direction = \"improved\" if diff > 0 else \"degraded\"\n        print(f\"   {abl_name}: {direction} by {abs(diff):.4f}\")\n\nprint(\"\\n4. STATISTICAL SIGNIFICANCE:\")\nif baseline_name in pivot_linear.columns:\n    sig_count = 0\n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            baseline_scores = pivot_linear[baseline_name].values\n            _, p_value = stats.ttest_rel(baseline_scores, comparison_scores)\n            if p_value < 0.05:\n                sig_count += 1\n    \n    print(f\"   {sig_count} out of {len(pivot_linear.columns)-1} ablations showed\")\n    print(f\"   statistically significant differences from baseline (p < 0.05)\")\n\nprint(\"\\n5. LABEL EFFICIENCY:\")\nbest_label_eff = results_df.groupby('ablation_name')['label_eff_10pct'].mean().idxmax()\nbest_label_eff_score = results_df.groupby('ablation_name')['label_eff_10pct'].mean().max()\nprint(f\"   Best label efficiency (10% labels): {best_label_eff}\")\nprint(f\"   Score: {best_label_eff_score:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 22: Export Final Summary Report\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPORTING SUMMARY REPORT\")\nprint(\"=\"*80)\n\n# Create comprehensive summary report\nreport_lines = []\n\nreport_lines.append(\"=\" * 80)\nreport_lines.append(\"TASK 7: ABLATION STUDY SUMMARY REPORT - SimCLR\")\nreport_lines.append(\"=\" * 80)\nreport_lines.append(\"\")\n\nreport_lines.append(\"EXPERIMENTAL SETUP:\")\nreport_lines.append(f\"  - Total ablation configurations: {len(ablation_configs)}\")\nreport_lines.append(f\"  - Train:test split ratios: {[r['name'] for r in split_ratios]}\")\nreport_lines.append(f\"  - Total experiments: {len(results_df)}\")\nreport_lines.append(\"\")\n\nreport_lines.append(\"ABLATION CONFIGURATIONS TESTED:\")\nfor i, cfg in enumerate(ablation_configs, 1):\n    report_lines.append(f\"  {i}. {cfg['name']}: {cfg['description']}\")\nreport_lines.append(\"\")\n\nreport_lines.append(\"STATISTICAL TESTS PERFORMED:\")\nreport_lines.append(\"  1. Paired t-tests (Baseline vs each ablation)\")\nreport_lines.append(\"  2. Friedman test (comparing all ablations)\")\nreport_lines.append(\"  3. Nemenyi post-hoc test (pairwise comparisons)\")\nreport_lines.append(\"  4. Effect size analysis (Cohen's d)\")\nreport_lines.append(\"\")\n\nreport_lines.append(\"KEY FINDINGS:\")\nreport_lines.append(f\"  Best ablation: {rankings.index[0]} (acc: {rankings.iloc[0]:.4f})\")\nreport_lines.append(f\"  Baseline: {baseline_name} (acc: {rankings[baseline_name]:.4f})\")\nreport_lines.append(f\"  Worst ablation: {rankings.index[-1]} (acc: {rankings.iloc[-1]:.4f})\")\nreport_lines.append(\"\")\n\n# Write to file\nwith open('ablation_summary_report.txt', 'w') as f:\n    f.write('\\n'.join(report_lines))\n\nprint(\"Summary report saved to: ablation_summary_report.txt\")\n\n# Save statistical test results\nstats_results = {\n    'paired_t_tests': [],\n    'friedman_test': None,\n}\n\nif baseline_name in pivot_linear.columns:\n    baseline_scores = pivot_linear[baseline_name].values\n    \n    for col in pivot_linear.columns:\n        if col != baseline_name:\n            comparison_scores = pivot_linear[col].values\n            t_stat, p_value = stats.ttest_rel(baseline_scores, comparison_scores)\n            \n            stats_results['paired_t_tests'].append({\n                'comparison': f\"{baseline_name} vs {col}\",\n                't_statistic': t_stat,\n                'p_value': p_value,\n                'significant': p_value < 0.05\n            })\n\n# Save as JSON\nimport json\nwith open('statistical_tests_results.json', 'w') as f:\n    json.dump(stats_results, f, indent=2)\n\nprint(\"Statistical test results saved to: statistical_tests_results.json\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"TASK 7 COMPLETED SUCCESSFULLY\")\nprint(\"=\"*80)\nprint(\"\\nGenerated files:\")\nprint(\"  1. ablation_results_simclr.csv - Full results table\")\nprint(\"  2. ablation_summary_report.txt - Summary report\")\nprint(\"  3. statistical_tests_results.json - Statistical test results\")\nprint(\"\\nAll visualizations displayed above.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}